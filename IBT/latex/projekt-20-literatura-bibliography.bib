  
    
    

    @webpage{hci,
      author =       "Jonák Zdeněk",
      title =        "Komunikace člověk-počítač",
      howpublished = "online",
      publisher =    "KTD: Česká terminologická databáze knihovnictví a~informační vědy (TDKIV)",
      year =         "2003",
      url =          "https://aleph.nkp.cz/F/?func=direct&doc_number=000000477&local_base=KTD",
      cited =        "2021-03-09"
    }
    
    @webpage{e4,
      publisher =       "Empatica",
      title =        "E4-wristband",
      howpublished = "online",
      year =         "2021",
      url =          "https://www.empatica.com/e4-wristband",
      cited =        "2021-03-09"
    }
    
    @webpage{web_ekg,
      publisher =       "Medicinská technika",
      title =        "EKG, Elektrokardiograf",
      howpublished = "online",
      year =         "2021",
      url =          "https://www.medicinskatechnika.cz/21-ekg",
      cited =        "2021-03-17"
    }
    
    @webpage{ wiki:commons,
        publisher = "Wikimedia Commons",
        title = "Main Page --- Wikimedia Commons{,} the free media repository",
        year = "2020",
        url = "https://commons.wikimedia.org/w/index.php?title=Main_Page&oldid=453255730",
        howpublished = "online",
        cited = "2021-03-16"
    }
    
    @webpage{ vykladovy_slovnik,
        publisher = "Univerzita Hradec Králové",
        title = "Výkladový slovník --- kognitivní věda :: UHK - Univerzita Hradec Králové",
        year = "2021",
        url = "http://fim2.uhk.cz/cogn/?Module=dictionary",
        howpublished = "online",
        cited = "2021-03-30"
    }
    
    
    
    @article {Cowen201702247,
	author = {Cowen, Alan S. and Keltner, Dacher},
	title = {Self-report captures 27 distinct categories of emotion bridged by continuous gradients},
	elocation-id = {201702247},
	year = {2017},
	doi = {10.1073/pnas.1702247114},
	publisher = {National Academy of Sciences},
	abstract = {Claims about how reported emotional experiences are geometrically organized within a semantic space have shaped the study of emotion. Using statistical methods to analyze reports of emotional states elicited by 2,185 emotionally evocative short videos with richly varying situational content, we uncovered 27 varieties of reported emotional experience. Reported experience is better captured by categories such as {\textquotedblleft}amusement{\textquotedblright} than by ratings of widely measured affective dimensions such as valence and arousal. Although categories are found to organize dimensional appraisals in a coherent and powerful fashion, many categories are linked by smooth gradients, contrary to discrete theories. Our results comprise an approximation of a geometric structure of reported emotional experience.Emotions are centered in subjective experiences that people represent, in part, with hundreds, if not thousands, of semantic terms. Claims about the distribution of reported emotional states and the boundaries between emotion categories{\textemdash}that is, the geometric organization of the semantic space of emotion{\textemdash}have sparked intense debate. Here we introduce a conceptual framework to analyze reported emotional states elicited by 2,185 short videos, examining the richest array of reported emotional experiences studied to date and the extent to which reported experiences of emotion are structured by discrete and dimensional geometries. Across self-report methods, we find that the videos reliably elicit 27 distinct varieties of reported emotional experience. Further analyses revealed that categorical labels such as amusement better capture reports of subjective experience than commonly measured affective dimensions (e.g., valence and arousal). Although reported emotional experiences are represented within a semantic space best captured by categorical labels, the boundaries between categories of emotion are fuzzy rather than discrete. By analyzing the distribution of reported emotional states we uncover gradients of emotion{\textemdash}from anxiety to fear to horror to disgust, calmness to aesthetic appreciation to awe, and others{\textemdash}that correspond to smooth variation in affective dimensions such as valence and dominance. Reported emotional states occupy a complex, high-dimensional categorical space. In addition, our library of videos and an interactive map of the emotional states they elicit (https://s3-us-west-1.amazonaws.com/emogifs/map.html) are made available to advance the science of emotion.},
	issn = {0027-8424},
	edition = {},
	number = {},
	URL = {https://www.pnas.org/content/early/2017/08/30/1702247114},
	eprint = {https://www.pnas.org/content/early/2017/08/30/1702247114.full.pdf},
	journal = {Proceedings of the National Academy of Sciences}
}

    
    
    
    
    @article{eye_tracking_setup,
        author = {Kővári, Attila and Katona, Jozsef and Pop, Cristina},
        year = {2020},
        month = {01},
        pages = {77-95},
        title = {Quantitative Analysis of Relationship Between Visual Attention and Eye-Hand Coordination},
        volume = {17},
        edition = {},
	    number = {},
        journal = {Acta Polytechnica Hungarica},
        doi = {10.12700/APH.17.2.2020.2.5}
    }
    
    @article{gaped,
        author = {Dan-Glauser, Elise and Scherer, Klaus},
        year = {2011},
        month = {03},
        pages = {468-77},
        title = {The Geneva affective picture database (GAPED): A new 730-picture database focusing on valence and normative significance},
        volume = {43},
        edition = {},
	    number = {},
        journal = {Behavior research methods},
        doi = {10.3758/s13428-011-0064-1}
    }
    
    @Article{oasis,
        author={Kurdi, Benedek
        and Lozano, Shayn
        and Banaji, Mahzarin R.},
        title={Introducing the Open Affective Standardized Image Set (OASIS)},
        journal={Behavior Research Methods},
        year={2017},
        month={Apr},
        day={01},
        volume={49},
        number={2},
        edition = {1},
        pages={457-470},
        abstract={We introduce the Open Affective Standardized Image Set (OASIS), an open-access online stimulus set containing 900 color images depicting a broad spectrum of themes, including humans, animals, objects, and scenes, along with normative ratings on two affective dimensions---valence (i.e., the degree of positive or negative affective response that the image evokes) and arousal (i.e., the intensity of the affective response that the image evokes). The OASIS images were collected from online sources, and valence and arousal ratings were obtained in an online study (total N = 822). The valence and arousal ratings covered much of the circumplex space and were highly reliable and consistent across gender groups. OASIS has four advantages: (a) the stimulus set contains a large number of images in four categories; (b) the data were collected in 2015, and thus OASIS features more current images and reflects more current ratings of valence and arousal than do existing stimulus sets; (c) the OASIS database affords users the ability to interactively explore images by category and ratings; and, most critically, (d) OASIS allows for free use of the images in online and offline research studies, as they are not subject to the copyright restrictions that apply to the International Affective Picture System. The OASIS images, along with normative valence and arousal ratings, are available for download from www.benedekkurdi.com/{\#}oasisor https://db.tt/yYTZYCga.},
        issn={1554-3528},
        doi={10.3758/s13428-016-0715-3},
        url={https://doi.org/10.3758/s13428-016-0715-3}
    }
    
    @article{Makowski2021neurokit,
    author={Makowski, Dominique and Pham, Tam and Lau, Zen J. and Brammer, Jan C. and Lespinasse, Fran{\c{c}}ois and Pham, Hung and Sch{\"o}lzel, Christopher and Chen, S. H. Annabel},
    title={NeuroKit2: A Python toolbox for neurophysiological signal processing},
    journal={Behavior Research Methods},
    year={2021},
    month={Feb},
    day={02},
    edition = {},
	number = {},
    issn={1554-3528},
    doi={10.3758/s13428-020-01516-y},
    url={https://doi.org/10.3758/s13428-020-01516-y}
    }
    
    @article{pyphysio,
    title = {pyphysio: A physiological signal processing library for data science approaches in physiology},
    journal = {SoftwareX},
    volume = {10},
    pages = {100287},
    year = {2019},
    edition = {},
	number = {},
    issn = {2352-7110},
    doi = {https://doi.org/10.1016/j.softx.2019.100287},
    url = {https://www.sciencedirect.com/science/article/pii/S2352711019301839},
    author = {Andrea Bizzego and Alessandro Battisti and Giulio Gabrieli and Gianluca Esposito and Cesare Furlanello},
    keywords = {Physiological signal processing, Psychophysiology, Autonomic indicators, Data science, Python},
    abstract = {The lack of open-source tools for physiological signal processing hinders the development of standardized pipelines in physiology. Researchers usually must rely on commercial software that, by implementing black-box algorithms, undermines the control on the analysis and prevents the comparison of the results, ultimately affecting the scientific reproducibility. We introduce pyphysio as a step towards a data science approach oriented to compute physiological indicators, in particular of the Autonomic Nervous System activity. pyphysio serves as a basis for machine learning modules and it implements a suite of combinable algorithms for processing of signals from either by wearable or medical-grade quality devices.}
    }
    
    @Article{CAP-D,
    author={Moyal, Natali
    and Henik, Avishai
    and Anholt, Gideon E.},
    title={Categorized Affective Pictures Database (CAP-D)},
    journal={Journal of cognition},
    year={2018},
    month={Sep},
    day={26},
    publisher={Ubiquity Press},
    volume={1},
    number={},
    edition = {},
    pages={41-41},
    keywords={Categorisation; Emotion and cognition; Stimulus development},
    abstract={Emotional picture databases are commonly used in emotion research. The databases were first based on ratings of emotional dimensions, and the interest in studying discrete emotions led to the categorization of subsets from these databases to emotional categories. However, to-date, studies that categorized affective pictures used confidence intervals in their analysis, a method that provides important data but also results in a high percentage of blended or undifferentiated categorization of images. The current study used 526 affective pictures from four databases and categorized the pictures to discrete emotions in two steps (Pre-testing phase {\&} Experiment 1). First, clinical psychologists were asked to generate emotional labels for each picture, according to the emotion the picture evoked in them. This resulted in the creation of 10 emotional categories. These labels were presented to students who were asked to choose the emotional category that matched the emotion a presented picture evoked in them. Agreement levels on the emotional categories were calculated for each picture, and pictures were categorized according to the most dominant emotion they evoked. The analysis of agreement levels rather than confidence intervals enabled us to provide both dominance of emotional category and agreement in the population regarding the dominance. In Experiment 2, we asked participants to provide ratings of emotional intensity and arousal, in order to provide more detailed information regarding the database. This is the first study to provide agreement levels on the categorization of affective pictures, and may be useful in various studies which aim at generating specific emotions.},
    note={31517214[pmid]},
    issn={2514-4820},
    doi={10.5334/joc.47},
    url={https://pubmed.ncbi.nlm.nih.gov/31517214},
    language={eng}
    }
    
    @article{DIRTI, 
    title={The DIsgust-RelaTed-Images (DIRTI) database: Validation of a novel standardized set of disgust pictures}, 
    volume={89}, DOI={10.1016/j.brat.2016.11.010}, 
    journal={Behaviour Research and Therapy}, 
    author={Haberkamp, Anke and Glombiewski, 
    Julia Anna and Schmidt, Filipp and Barke, Antonia},
    year={2017}, 
    edition = {},
	number = {},
    pages={86–94}
    }
    
    @Article{SFIP,
    author={Micha{\l}owski, Jaros{\l}aw M.
    and Dro{\'{z}}dziel, Dawid
    and Matuszewski, Jacek
    and Koziejowski, Wojtek
    and Jednor{\'o}g, Katarzyna
    and Marchewka, Artur},
    title={The Set of Fear Inducing Pictures (SFIP): Development and     validation in fearful and nonfearful individuals},
    journal={Behavior Research Methods},
    year={2017},
    month={Aug},
    day={01},
    volume={49},
    number={4},
    edition = {1},
    pages={1407-1419},
    abstract={Emotionally charged pictorial materials are frequently used in phobia research, but no existing standardized picture database is dedicated to the study of different phobias. The present work describes the results of two independent studies through which we sought to develop and validate this type of database---a Set of Fear Inducing Pictures (SFIP). In Study 1, 270 fear-relevant and 130 neutral stimuli were rated for fear, arousal, and valence by four groups of participants; small-animal (N = 34), blood/injection (N = 26), social-fearful (N = 35), and nonfearful participants (N = 22). The results from Study 1 were employed to develop the final version of the SFIP, which includes fear-relevant images of social exposure (N = 40), blood/injection (N = 80), spiders/bugs (N = 80), and angry faces (N = 30), as well as 726 neutral photographs. In Study 2, we aimed to validate the SFIP in a sample of spider, blood/injection, social-fearful, and control individuals (N = 66). The fear-relevant images were rated as being more unpleasant and led to greater fear and arousal in fearful than in nonfearful individuals. The fear images differentiated between the three fear groups in the expected directions. Overall, the present findings provide evidence for the high validity of the SFIP and confirm that the set may be successfully used in phobia research.},
    issn={1554-3528},
    doi={10.3758/s13428-016-0797-y},
    url={https://doi.org/10.3758/s13428-016-0797-y}
    }
    
    @article{SMID,
    doi = {10.1371/journal.pone.0190954},
    author = {Crone, Damien L. and Bode, Stefan and Murawski, Carsten and Laham, Simon M.},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {The Socio-Moral Image Database (SMID): A novel stimulus set for the study of social, moral and affective processes},
    year = {2018},
    month = {01},
    volume = {13},
    edition = {1},
    url = {https://doi.org/10.1371/journal.pone.0190954},
    pages = {1-34},
    abstract = {A major obstacle for the design of rigorous, reproducible studies in moral psychology is the lack of suitable stimulus sets. Here, we present the Socio-Moral Image Database (SMID), the largest standardized moral stimulus set assembled to date, containing 2,941 freely available photographic images, representing a wide range of morally (and affectively) positive, negative and neutral content. The SMID was validated with over 820,525 individual judgments from 2,716 participants, with normative ratings currently available for all images on affective valence and arousal, moral wrongness, and relevance to each of the five moral values posited by Moral Foundations Theory. We present a thorough analysis of the SMID regarding (1) inter-rater consensus, (2) rating precision, and (3) breadth and variability of moral content. Additionally, we provide recommendations for use aimed at efficient study design and reproducibility, and outline planned extensions to the database. We anticipate that the SMID will serve as a useful resource for psychological, neuroscientific and computational (e.g., natural language processing or computer vision) investigations of social, moral and affective processes. The SMID images, along with associated normative data and additional resources are available at https://osf.io/2rqad/.},
    number = {1},

    }
    
    @article{detection_stress,
    author = {Palanisamy, Karthikeyan and M, Murugappan and Yaacob, Sazali},
    year = {2013},
    month = {04},
    pages = {},
    title = {Detection of human stress using short-term ECG and HRV signals},
    volume = {13},
    edition = {},
	number = {},
    journal = {Journal of Mechanics in Medicine and Biology},
    doi = {10.1142/S0219519413500383}
    }
    
  
    
    
    @ARTICLE{audio_stimuli,
    AUTHOR={Idrobo-Ávila, Ennio H. and Loaiza-Correa, Humberto and van Noorden, Leon and Muñoz-Bolaños, Flavio G. and Vargas-Cañas, Rubiel},   
    TITLE={Different Types of Sounds and Their Relationship With the Electrocardiographic Signals and the Cardiovascular System – Review},  
    JOURNAL={Frontiers in Physiology},      
    VOLUME={9},      
    PAGES={525},     
    YEAR={2018},      
    URL={https://www.frontiersin.org/article/10.3389/fphys.2018.00525},      
    DOI={10.3389/fphys.2018.00525},      
    ISSN={1664-042X},   
    edition = {},
	number = {},
    ABSTRACT={Background: For some time now, the effects of sound, noise, and music on the human body have been studied. However, despite research done through time, it is still not completely clear what influence, interaction, and effects sounds have on human body. That is why it is necessary to conduct new research on this topic. Thus, in this paper, a systematic review is undertaken in order to integrate research related to several types of sound, both pleasant and unpleasant, specifically noise and music. In addition, it includes as much research as possible to give stakeholders a more general vision about relevant elements regarding methodologies, study subjects, stimulus, analysis, and experimental designs in general. This study has been conducted in order to make a genuine contribution to this area and to perhaps to raise the quality of future research about sound and its effects over ECG signals.Methods: This review was carried out by independent researchers, through three search equations, in four different databases, including: engineering, medicine, and psychology. Inclusion and exclusion criteria were applied and studies published between 1999 and 2017 were considered. The selected documents were read and analyzed independently by each group of researchers and subsequently conclusions were established between all of them.Results: Despite the differences between the outcomes of selected studies, some common factors were found among them. Thus, in noise studies where both BP and HR increased or tended to increase, it was noted that HRV (HF and LF/HF) changes with both sound and noise stimuli, whereas GSR changes with sound and musical stimuli. Furthermore, LF also showed changes with exposure to noise.Conclusion: In many cases, samples displayed a limitation in experimental design, and in diverse studies, there was a lack of a control group. There was a lot of variability in the presented stimuli providing a wide overview of the effects they could produce in humans. In the listening sessions, there were numerous examples of good practice in experimental design, such as the use of headphones and comfortable positions for study subjects, while the listening sessions lasted 20 min in most of the studies.}
    }
    
    
    
    @ARTICLE{video_emotion,
    author={Song, Tengfei and Zheng, Wenming and Lu, Cheng and Zong, Yuan and Zhang, Xilei and Cui, Zhen},
    journal={IEEE Access},
    title={MPED: A Multi-Modal Physiological Emotion Database for Discrete Emotion Recognition},
    year={2019},
    volume={7},
    number={},
    edition = {},
    pages={12177-12191},
    doi={10.1109/ACCESS.2019.2891579}
    }
    
    @inproceedings{herbon2006emotions,
     title={Emotions in ambient intelligence-an experiment on how to measure affective states},
     author={Herbon, Antje and Oehme, Astrid and Zentsch, Eric},
     booktitle={Emotions in HCI Workshop at HCI},
     pages={90},
     year={2006}
    }
    
    @inproceedings{sliding_window,
    author = {Bracale, Antonio and Carpinelli, Guido and Lauria, D. and Leonowicz, Zbigniew and Lobos, T. and Rezmer, J.},
    year = {2004},
    month = {10},
    pages = {266 - 271},
    title = {On Some Spectrum Estimation Methods for Analysis of Non-Stationary Signals in Power Systems Part I: Theoretical Aspects},
    isbn = {0-7803-8746-5},
    doi = {10.1109/ICHQP.2004.1409365}
    }
    
    @inproceedings{fps_emotions,
    author = {Drachen, Anders and Nacke, Lennart E. and Yannakakis, Georgios and Pedersen, Anja Lee},
    title = {Correlation between Heart Rate, Electrodermal Activity and Player Experience in First-Person Shooter Games},
    year = {2010},
    isbn = {9781450300971},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/1836135.1836143},
    doi = {10.1145/1836135.1836143},
    abstract = {Psychophysiological methods are becoming more popular in game research as covert and reliable measures of affective player experience, emotions, and cognition. Since player experience is not well understood, correlations between self-reports from players and psychophysiological data may provide a quantitative understanding of this experience. Measurements of electrodermal activity (EDA) and heart rate (HR) allow making inferences about player arousal (i.e., excitement) and are easy to deploy. This paper reports a case study on HR and EDA correlations with subjective gameplay experience, testing the feasibility of these measures in commercial game development contexts. Results indicate a significant correlation (p &lt; 0.01) between psychophysiological arousal (i.e., HR, EDA) and self-reported gameplay experience. However, the covariance between psychophysiological measures and self-reports varies between the two measures. The results are consistent across three different contemporary major commercial first-person shooter (FPS) games (Prey, Doom 3, and Bioshock).},
    booktitle = {Proceedings of the 5th ACM SIGGRAPH Symposium on Video Games},
    pages = {49–54},
    numpages = {6},
    keywords = {player experience, user experience (UX), digital games, user studies, affective gaming, entertainment, psychophysiology, analysis, human-centered design},
    location = {Los Angeles, California},
    series = {Sandbox '10}
    }
    
    @INPROCEEDINGS{vr_emotions,  
    author={Egan, Darragh and Brennan, Sean and Barrett, John and Qiao, Yuansong and Timmerer, Christian and Murray, Niall},
    booktitle={2016 Eighth International Conference on Quality of Multimedia Experience (QoMEX)},   
    title={An evaluation of Heart Rate and ElectroDermal Activity as an objective QoE evaluation method for immersive virtual reality environments},
    year={2016},
    volume={},
    number={},
    pages={1-6},
    doi={10.1109/QoMEX.2016.7498964}}
    
    @inproceedings{wearable_emotion_gaped,
    author = {Udovi\v{c}i\'{c}, Goran and \DH{}erek, Jurica and Russo, Mladen and Sikora, Marjan},
    title = {Wearable Emotion Recognition System Based on GSR and PPG Signals},
    year = {2017},
    isbn = {9781450355049},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3132635.3132641},
    doi = {10.1145/3132635.3132641},
    abstract = {In recent years, many methods and systems for automated recognition of human emotional states were proposed. Most of them are trying to recognize emotions based on physiological signals such as galvanic skin response (GSR), electrocardiogram (ECG), electroencephalogram (EEG), electromyogram (EMG), photoplethysmogram (PPG), respiration, skin temperature etc. Measuring all these signals is quite impractical for real-life use and in this research, we decided to acquire and analyse only GSR and PPG signals because of its suitability for implementation on a simple wearable device that can collect signals from a person without compromising comfort and privacy. For this purpose, we used the lightweight, small and compact Shimmer3 sensor. We developed complete application with database storage to elicit participant»s emotions using pictures from the Geneva affective picture database (GAPED) database. In the post-processing process, we used typical statistical parameters and power spectral density (PSD) as features and support vector machine (SVM) and k-nearest neighbours (KNN) as classifiers. We built single-user and multi-user emotion classification models to compare the results. As expected, we got better average accuracies on a single-user model than on the multi-user model. Our results also show that a single-user based emotion detection model could potentially be used in real-life scenario considering environments conditions.},
    booktitle = {Proceedings of the 2nd International Workshop on Multimedia for Personal Health and Health Care},
    pages = {53–59},
    numpages = {7},
    keywords = {emotion classification, signal processing, physiological     signals, affective computing, ppg, gsr, wearable devices},
    location = {Mountain View, California, USA},
    series = {MMHealth '17}
    }
    
    

    @INPROCEEDINGS{e4_validation,
      author={McCarthy, Cameron and Pradhan, Nikhilesh and Redpath, Calum and Adler, Andy},
      booktitle={2016 IEEE EMBS International Student Conference (ISC)}, 
      title={Validation of the Empatica E4 wristband}, 
      year={2016},
      volume={},
      number={},
      pages={1-4},
      doi={10.1109/EMBSISC.2016.7508621},
      isbn={978-1-5090-0936-7}
    }

    @INPROCEEDINGS{e4_reliability,
      author={Borrego, Adrian and Latorre, Jorge and Alcañiz, Mariano and Llorens, Roberto},
      booktitle={2019 International Conference on Virtual Rehabilitation (ICVR)}, 
      title={Reliability of the Empatica E4 wristband to measure electrodermal activity to emotional stimuli}, 
      year={2019},
      volume={},
      number={},
      pages={1-2},
      doi={10.1109/ICVR46560.2019.8994546},
      isbn={978-1-7281-1286-2},
      issn={2331-9569}
    }


    @INPROCEEDINGS{e4_stress_detection,
        author={Ollander, Simon and Godin, Christelle and Campagne, Aurélie and Charbonnier, Sylvie},
        booktitle={2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
        title={A comparison of wearable and stationary sensors for stress detection}, 
        year={2016},
        volume={},
        number={},
        pages={004362-004366},
        doi={10.1109/SMC.2016.7844917},
        isbn={978-1-5090-1898-7},
        issn={}
    }




    @BOOK{eda_book,
      author =       "Wolfram Boucsein",
      title =        "Electrodermal Activity",
      publisher =    "Springer US",
      year =         "2012",
      edition =      "1",
      isbn =         "978-1-4614-1125-3",
    }
    
    @misc{ wiki:ergonomie,
        author = "Wikipedie",
        title = "Ergonomie --- Wikipedie: Otevřená encyklopedie",
        year = "2021",
        url = "https://cs.wikipedia.org/w/index.php?title=Ergonomie&oldid=19503428",
        howpublished = "online",
        cited = "2021-03-22"
    }
    
    @misc{eda,
        author = "{Wikipedia contributors}",
        title = "Funkce buněk a lidského těla",
        year = "2021",
        url = "https://en.wikipedia.org/w/index.php?title=Electrodermal_activity&oldid=1006473698",
        howpublished = "online",
        cited = "2021-03-10"
    }
    
    @misc{ wiki:fyzio,
     author = "Wikipedie",
     title = "Fyziologie člověka --- Wikipedie: Otevřená encyklopedie",
     year = "2017",
     url = "https://cs.wikipedia.org/w/index.php?title=Fyziologie_\%C4\%8Dlov\%C4\%9Bka&oldid=15427713",
     howpublished = "online",
     cited = "2021-03-10"
    }
    
    @misc{ what_is_UX,
        author = "LISTIFY",
        title = "Co je to česky „User Experience“ – UX design?",
        year = "2021",
        url = "https://www.listify.cool/co-je-to-cesky-user-experience-ux-design/",
        howpublished = "online",
        cited = "2021-03-16"
    }
    
     @misc{ wiki_ans,
        author = "WikiSkripta",
        title = "Vegetativní nervová soustava (fyziologie) --- ",
        year = "2020",
        url = "https://www.wikiskripta.eu/index.php?title=Vegetativn\%C3\%AD_nervov\%C3\%A1_soustava_(fyziologie)&oldid=440025",
        howpublished = "online",
        cited = "2021-03-16"
    }
    
     @misc{ ans,
        author = "MUDr. Josef Fontana and doc. MUDr. Jan Trnka, Ph.D. and others",
        title = "Vegetativní nervová soustava (fyziologie) --- ",
        year = "2020",
        url = "http://fblt.cz/skripta/regulacni-mechanismy-2-nervova-regulace/6-autonomni-nervovy-system/",
        howpublished = "online",
        cited = "2021-03-16"
    }
    
     @misc{ ans_s_p,
        author = "Petr Kosik",
        title = "Autonomní nervový systém",
        year = "2017",
        url = "https://wikisofia.cz/w/index.php?title=Autonomn\%C3\%AD_nervov\%C3\%BD_syst\%C3\%A9m&oldid=49200",
        howpublished = "online",
        cited = "2021-03-16"
    }
    
    @misc{ wiki_ecg,
        author = "Wikipedie",
        title = "Elektrokardiogram --- Wikipedie: Otevřená encyklopedie",
        year = "2020",
        url = "https://cs.wikipedia.org/w/index.php?title=Elektrokardiogram&oldid=18257080",
        howpublished = "online",
        cited = "2021-03-16"
    }
    
    
    
    @misc{ wiki:fyzio_sledovani,
     author = "WikiSkripta",
     title = "Sledování fyziologických funkcí --- ",
     year = "2021",
     url = "https://www.wikiskripta.eu/index.php?title=Sledov\%C3\%A1n\%C3\%AD_fyziologick\%C3\%BDch_funkc\%C3\%AD&oldid=446279",
     howpublished = "online",
     cited = "2021-03-10"
    }
    
    @misc{ wiki_eeg,
        author = "WikiSkripta",
        title = "Elektroencefalografie --- ",
        year = "2021",
        url = "https://www.wikiskripta.eu/index.php?title=Elektroencefalografie&oldid=445078",
        howpublished = "online",
        cited = "2021-03-17"
    }
    
    
    @misc{ empatica_support,
     author = "Empatica",
     title = "E4 data --- BVP expected signal",
     year = "2020",
     url = "https://support.empatica.com/hc/en-us/articles/360029719792-E4-data-BVP-expected-signal",
     howpublished = "online",
     cited = "2021-03-16"
    }
    
    
 
    